{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bptripp/ai-course/blob/main/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CMfJI4hQ76"
      },
      "source": [
        "#Categorizing Images with Convolutional Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3xs-nZyx5g3"
      },
      "source": [
        "Below are some import statements and the class definition for a small convolutional network that you have seen earlier, which is meant to classify images of handwritten digits. Run this code to get started.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3PxLa0yCgwCw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DigitNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DigitNetwork, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout = nn.Dropout2d(.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = self.conv1(input)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds2yfn5T3FnX"
      },
      "source": [
        "Digit recognition was the first task to which convolutional networks were applied in the 1980s. The motivation was to automatically sort US mail by ZIP code. To help solve this problem, a set of 70,000 digit images was curated in the Modified National Institute of Standards and Technology (MNIST) dataset (https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "We will now load the MNIST data and train a DigitNetwork with it. MNIST is one of the most popular machine learning datasets, so pytorch knows where it is on the internet and will download it for us. The code below will also prepare training and testing datasets and corresponding \"DataLoader\" objects that provide batches of examples from these datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5815k83SL_3",
        "outputId": "7e2b9586-1690-470c-b4ab-61f3f78acf27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 343919257.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28131837.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 171725260.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5223616.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "directory = 'data' # where we will save the dataset on this server\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST(directory, train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(directory, train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 1000 # the size of a group of examples we will process at once\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# image_datasets = {'train': train_set, 'validation': test_set}\n",
        "# dataloaders = {'train': train_loader, 'validation': test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HikKs3zNa-Qn"
      },
      "source": [
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ufk4ZOEFnU-R"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def process_batch(model, inputs, labels, optimizer=None):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  if optimizer is not None:\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  _, predictions = torch.max(outputs, 1)\n",
        "  fraction_correct = torch.sum(predictions == labels.data).item() / len(predictions)\n",
        "\n",
        "  return loss.item(), fraction_correct\n",
        "\n",
        "\n",
        "def loop_through_batches(model, loader, optimizer=None):\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for inputs, labels in loader:\n",
        "      print('.', end='')\n",
        "      batch_loss, batch_acc = process_batch(model, inputs, labels, optimizer=optimizer)\n",
        "      losses.append(batch_loss)\n",
        "      accuracies.append(batch_acc)\n",
        "\n",
        "    print('{} loss: {:.4f} accuracy: {:.4f}'.format(\n",
        "        'Validation' if optimizer is None else 'Training',\n",
        "        np.mean(losses),\n",
        "        np.mean(accuracies)))\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, num_epochs):\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "\n",
        "    model.train() # put model in training mode\n",
        "    loop_through_batches(model, train_loader, optimizer=optimizer)\n",
        "\n",
        "    model.eval() # put model in evaluation mode\n",
        "    loop_through_batches(model, validation_loader)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwIkE06W6q9O",
        "outputId": "a462ccab-b630-4a7e-9818-204a0d6c36bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WCnfUumdGNq",
        "outputId": "6499a769-6093-44f0-a583-3fe2b7095dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "............................................................Training loss: 0.9431 accuracy: 0.7251\n",
            "..........Validation loss: 0.2552 accuracy: 0.9251\n",
            "Epoch 2/3\n",
            "............................................................Training loss: 0.2399 accuracy: 0.9292\n",
            "..........Validation loss: 0.1619 accuracy: 0.9490\n",
            "Epoch 3/3\n",
            "............................................................Training loss: 0.1614 accuracy: 0.9526\n",
            "..........Validation loss: 0.1051 accuracy: 0.9683\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "\n",
        "model = DigitNetwork()\n",
        "model.to(device);\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "train_model(model, optimizer, 3);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v0CMfJI4hQ76"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNMz0ClvF8CK8BvjaisYmfw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
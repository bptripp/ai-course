{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bptripp/ai-course/blob/main/pneumonia_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgKJv6ABfCPZ"
      },
      "source": [
        "# Transfer Learning for Pneumonia Detection\n",
        "In this activity you will use a convolutional network for detection of pneumonia in chest radiographs. This is a more difficult task than classifying digits, so it will require a larger network.\n",
        "\n",
        "Training such a network from scratch would take several days and would require a large number of labelled examples. However, one can often get away with less training and less data by starting with a network that has already been trained for a related task.\n",
        "\n",
        "For vision tasks, it is common to begin with a network that has been trained on ImageNet-1K, a dataset of over a million images of objects that are labelled with 1000 categories, including different kinds of animals, vehicles, etc.\n",
        "\n",
        "Detecting pneumonia in chest radiographs is quite different, even in terms of image statistics, so it is not clear in advance how well this approach will work for this problem.\n",
        "\n",
        "You should run the code for this example on a graphical processing unit (GPU). Before proceeding, select \"Change runtime type\" from the \"Runtime\" menu, and select a GPU option from among the \"Hardware accelerator\" choices. Default values are fine for any other choices.\n",
        "\n",
        "*After selecting a GPU option, run the code below to import some required libraries and confirm that you are using a GPU. This code should print \"cuda:0\". If it prints \"cpu\" instead, check your hardware accelerator setting and try again.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JtaQgJXyaoB",
        "outputId": "30bfa684-227e-4aeb-c6a0-f7f6265a1dcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch has a number of built-in convolutional networks that have been pre-trained on ImageNet, so it is easy to download one and use it. ResNet50 is an effective network for many visual classication tasks.\n",
        "\n",
        "*Run the code below to download a convolutional network that has already been trained on ImageNet.*"
      ],
      "metadata": {
        "id": "N0B1CW8ByeyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "maBbdEx3et42"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqjj5ooOYNH9"
      },
      "source": [
        "For your interest, print the network structure by running the code below.\n",
        "\n",
        "*Optionally run this code to print the network structure.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ9yRX_8T9Kc"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfI9hy4YyPW"
      },
      "source": [
        "The next step is to make some changes to the network to prepare it for the new task. First, you will \"freeze\" the existing network parameters so that they do not change during subsequent training. The network will therefore continue to calculate the features it learned on ImageNet.\n",
        "\n",
        "Second, you will replace the model's final \"fully-connected\" layer with three new layers. These new layers will learn to use the network's ImageNet-trained features for the new task of pneumonia detection.\n",
        "\n",
        "*Run the code below to freeze the existing network parameters and replace the exisiting ImageNet-trained output layer with new randomly initialized layers.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XUBp3JiPUZ1r"
      },
      "outputs": [],
      "source": [
        "# freeze existing network parameters\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "# replace final fully-connected layer with two new layers\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 64),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(64, 64),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(64, 2))\n",
        "\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHDeYKuLaGSy"
      },
      "source": [
        "The network is now ready to learn pneumonia detection, but it needs a labelled dataset for this purpose. You will use the data from this paper:\n",
        "\n",
        "Kermany, D. S., Goldbaum, M., Cai, W., Valentim, C. C., Liang, H., Baxter, S. L., ... & Zhang, K. (2018). Identifying medical diagnoses and treatable diseases by image-based deep learning. Cell, 172(5), 1122-1131.\n",
        "\n",
        "The dataset is available from https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia. Downloading it, moving it to this server, and unzipping it would normally involve some manual steps. However, the dataset has been copied to a convenient location so that the code below can perform these steps automatically. This is possible because the paper's authors made the dataset available under a Creative Commons License. This copy of the dataset has not been altered.\n",
        "\n",
        "*Run the code below to download the dataset to this server and unzip it.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7QanaFCewkW",
        "outputId": "d5bfacf7-29cc-4bc2-e1e9-3184adba9e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-25 18:58:23--  http://bptripp.com/Kermany-Chest-XRay-Data.zip\n",
            "Resolving bptripp.com (bptripp.com)... 64.90.50.171\n",
            "Connecting to bptripp.com (bptripp.com)|64.90.50.171|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1237670572 (1.2G) [application/zip]\n",
            "Saving to: ‘Kermany-Chest-XRay-Data.zip.1’\n",
            "\n",
            "Kermany-Chest-XRay- 100%[===================>]   1.15G  71.9MB/s    in 18s     \n",
            "\n",
            "2023-09-25 18:58:41 (66.9 MB/s) - ‘Kermany-Chest-XRay-Data.zip.1’ saved [1237670572/1237670572]\n",
            "\n",
            "replace __MACOSX/._chest_xray? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!wget bptripp.com/Kermany-Chest-XRay-Data.zip\n",
        "!unzip -q Kermany-Chest-XRay-Data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPFfI7jEqB2C"
      },
      "source": [
        "Similar to the process for training the digit recognition network, the next step is to create data loaders. The code is slightly different in this case, in part because this dataset is not built in to PyTorch.  \n",
        "\n",
        "*Run the code below to create dataloaders that provide batches of training and validation examples.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aMWKAyUumQ8R"
      },
      "outputs": [],
      "source": [
        "# Normalize images in the same way images are normalized for ImageNet\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# This \"transform\" object will perform a few simple operations to turn images\n",
        "# into suitable network inputs. One operation is to tilt images a little bit at random\n",
        "# each time they are presented to the network. This is a kind of dataset\n",
        "# augmentation that helps the network get more out of limited training data.\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(8, shear=8),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "\n",
        "input_path = 'chest_xray/'\n",
        "train_set = datasets.ImageFolder(input_path + 'train', transform)\n",
        "validation_set = datasets.ImageFolder(input_path + 'test', transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, as in the MNIST example, you will create a function to process all the batches in a given dataset. There are various ways to organize such code, but for simplicity, the code below is essentially the same as the corresponding code in the MNIST example."
      ],
      "metadata": {
        "id": "XFXRq4Bd3c4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(model, loader, optimizer=None):\n",
        "  \"\"\"\n",
        "  model: the deep network\n",
        "  loader: the dataloader of the dataset that is to be procesed\n",
        "  optimizer: an object that updates the network's parameters\n",
        "  \"\"\"\n",
        "\n",
        "  # create lists of losses and accuracies for each batch in the dataset\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "\n",
        "  for batch_num, (inputs, targets) in enumerate(loader): # loop through all the batches\n",
        "    if batch_num % 2 == 1:\n",
        "      print('.', end='') # print a dot every other batch (as a progress bar)\n",
        "\n",
        "    inputs = inputs.to(device) # move inputs to the GPU\n",
        "    targets = targets.to(device) # move labels to the GPU\n",
        "    outputs = model(inputs) # run the inputs through the network\n",
        "    loss = nn.CrossEntropyLoss()(outputs, targets) # calculate the loss\n",
        "\n",
        "    if optimizer is not None:\n",
        "      optimizer.zero_grad() # delete any gradients from previous steps\n",
        "      loss.backward() # perform backpropagation to calculate new gradients\n",
        "      optimizer.step() # perform gradient descent to improve parameters\n",
        "\n",
        "    # calculate the fraction of predictions in this batch that were correct\n",
        "    predictions = outputs.argmax(dim=1) # the predicted category corresponds to the output neurons with highest value\n",
        "    fraction_correct = torch.sum(predictions == targets.data).item() / len(predictions)\n",
        "\n",
        "    # add this batch's loss and fraction-correct to the lists\n",
        "    losses.append(loss.item())\n",
        "    accuracies.append(fraction_correct)\n",
        "\n",
        "  # print the average loss and accuracy over the whole dataset\n",
        "  print('{} loss: {:.4f} accuracy: {:.4f}'.format(\n",
        "      'Validation' if optimizer is None else 'Training',\n",
        "      np.mean(losses),\n",
        "      np.mean(accuracies)))"
      ],
      "metadata": {
        "id": "F8U6QBm95qW6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are ready to train the network. As in the MNIST example, the code below runs several epochs of training, and prints the loss and accuracy on the validation dataset after each epoch. This is a more difficult problem than digit recognition, so the accuracy will not be as high after a few minutes of training, and accuracy may not increase monotonically.\n",
        "\n",
        "*Run the code below to partially train the network.*"
      ],
      "metadata": {
        "id": "63w_PCyqxPGs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5aq0g3vnD-r",
        "outputId": "5b51f0bb-533a-4d0c-ef53-690df717aa1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "..................................................................................Training loss: 0.2616 accuracy: 0.8929\n",
            "..........Validation loss: 0.7176 accuracy: 0.7484\n",
            "Epoch 2/5\n",
            "..................................................................................Training loss: 0.1575 accuracy: 0.9354\n",
            "..........Validation loss: 0.5707 accuracy: 0.8063\n",
            "Epoch 3/5\n",
            "..................................................................................Training loss: 0.1548 accuracy: 0.9396\n",
            "..........Validation loss: 0.3417 accuracy: 0.8578\n",
            "Epoch 4/5\n",
            "..................................................................................Training loss: 0.1624 accuracy: 0.9333\n",
            "..........Validation loss: 0.6229 accuracy: 0.7906\n",
            "Epoch 5/5\n",
            "..................................................................................Training loss: 0.1550 accuracy: 0.9421\n",
            "..........Validation loss: 0.4000 accuracy: 0.8625\n"
          ]
        }
      ],
      "source": [
        "# this optimizer implements a more complex variation of gradient descent\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.005, weight_decay=1e-6)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "\n",
        "    model.train() # put model in training mode\n",
        "    process_dataset(model, train_loader, optimizer=optimizer)\n",
        "\n",
        "    model.eval() # this disables things like dropout that are only beneficial during training\n",
        "    process_dataset(model, validation_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
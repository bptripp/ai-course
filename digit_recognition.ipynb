{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bptripp/ai-course/blob/main/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CMfJI4hQ76"
      },
      "source": [
        "#Categorizing Images with Convolutional Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is usually much faster to train a deep network on a graphical processing unit (GPU) than a computer's standard central processing unit (CPU). Before proceeding, select \"Change runtime type\" from the \"Runtime\" menu, and make sure a GPU option is selected from among the \"Hardware accelerator\" choices. Default values are fine for any other choices.\n",
        "\n",
        "Once you have done that, the code below should print \"cuda:0\". CUDA stands for Compute Unified Device Architecture. It is a low-level interface that PyTorch uses to run code on a GPU. If it says \"cpu\" then check your hardware accelerator and try again.\n",
        "\n",
        "*Run the code below to create a code reference to the GPU \"device\".*"
      ],
      "metadata": {
        "id": "oegSbJgpHX6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLprHsLqHZzH",
        "outputId": "906db733-f8f8-4ff8-cca9-d47711dc8231"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3xs-nZyx5g3"
      },
      "source": [
        "The code below imports some packages and defines a small convolutional network class similar to the one you saw earlier. It is meant to classify images of handwritten digits from 0-9.\n",
        "\n",
        "*Run this code to get started.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3PxLa0yCgwCw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNetwork, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout = nn.Dropout2d(.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = self.conv1(input)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds2yfn5T3FnX"
      },
      "source": [
        "Digit recognition was the first thing convolutional networks were used for in the 1980s. The motivation was to automatically sort US mail by ZIP code. To help solve this problem, a set of 70,000 digit images was curated in the Modified National Institute of Standards and Technology (MNIST) dataset (https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "You should now obtain the MNIST data so that you can use it to train the network. MNIST is one of the most popular machine learning datasets, so PyTorch knows where it is and will download it for you. The code below will also prepare training and testing subsets of the data and corresponding \"DataLoader\" objects that organize the examples in these datasets into \"batches\". The network will process one batch of examples at a time.\n",
        "\n",
        "*Run the code below to download and organize the data.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I5815k83SL_3"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "directory = 'data' # the folder where the dataset will be saved on this server\n",
        "\n",
        "# this object will put images in the right form for input to the network\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# these objects contain training and testing subsets of the data\n",
        "train_set = datasets.MNIST(directory, train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(directory, train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 1000 # the size of groups of examples that are used for gradient descent steps\n",
        "\n",
        "#these \"loader\" objects will provide batches of examples from the datasets\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have defined the ConvolutionalNetwork class, but you still have to create an object of that class. A technical detail in using the network object is that the GPU has its own on-board memory, and the network must be moved to that memory in order to run efficiently.\n",
        "\n",
        "You will also need an \"optimizer\" object to update the network's parameters based on the gradient of the loss for each batch. Create an optimizer object of the SGD class (for \"stochastic gradient descent\") that comes with PyTorch's \"optim\" package. This code also sets the optimizer's \"learning rate\" parameter, which determines the size of gradient descent steps. If this is too big, the network may skip right over the best parameters and become worse with training.\n",
        "\n",
        "*Run the code below to create network and optimizer objects and move the network to the GPU.*"
      ],
      "metadata": {
        "id": "TYckAzaKem7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvolutionalNetwork()\n",
        "model.to(device) # move model to GPU\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1) # lr is the learning rate"
      ],
      "metadata": {
        "id": "gvToZBPffk60"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HikKs3zNa-Qn"
      },
      "source": [
        "You will now create a function that loops through all the batches of image/label examples in a given dataset, runs them through the network, and keeps track of the average loss and accuracy. This function can optionally receive your optimizer object as a parameter, in which case it will also perform backpropagation and gradient descent to update the parameters.   \n",
        "\n",
        "*Run the code below to create a function that passes a dataset through the network.*  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(model, loader, optimizer=None):\n",
        "  \"\"\"\n",
        "  model: the deep network\n",
        "  loader: the dataloader of the dataset that is to be procesed\n",
        "  optimizer: an object that updates the network's parameters\n",
        "  \"\"\"\n",
        "\n",
        "  # create lists of losses and accuracies for each batch in the dataset\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "\n",
        "  for inputs, labels in loader: # this is a loop through all the batches\n",
        "    print('.', end='') # prints a dot for each batch (this serves as a progress bar)\n",
        "\n",
        "    inputs = inputs.to(device) # move inputs to the GPU\n",
        "    labels = labels.to(device) # move labels to the GPU\n",
        "    outputs = model(inputs) # run the inputs through the network\n",
        "    loss = nn.CrossEntropyLoss()(outputs, labels) # calculate the loss\n",
        "\n",
        "    if optimizer is not None:\n",
        "      optimizer.zero_grad() # delete any gradients from previous steps\n",
        "      loss.backward() # perform backpropagation to calculate new gradients\n",
        "      optimizer.step() # perform gradient descent to improve parameters\n",
        "\n",
        "    # calculate the fraction of predictions in this batch that were correct\n",
        "    _, predictions = torch.max(outputs, 1) # predicted digits are output neurons with highest values\n",
        "    fraction_correct = torch.sum(predictions == labels.data).item() / len(predictions)\n",
        "\n",
        "    # add this batch's loss and fraction-correct to the lists\n",
        "    losses.append(loss.item())\n",
        "    accuracies.append(fraction_correct)\n",
        "\n",
        "  # print the average loss and accuracy over the whole dataset\n",
        "  print('{} loss: {:.4f} accuracy: {:.4f}'.format(\n",
        "      'Validation' if optimizer is None else 'Training',\n",
        "      np.mean(losses),\n",
        "      np.mean(accuracies)))"
      ],
      "metadata": {
        "id": "slFiZTw_8cBE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now everything is ready to train the network. You are using a GPU, you have network and optimizer objects, you have downloaded the data and created data loaders to access it one batch at a time. You also have a function that runs all the batches in a dataset through the network, calculates the average loss and accuracy, and updates the parameters as needed.\n",
        "\n",
        "The code below runs several \"epochs\" (passes through the dataset) of training. After each epoch, the code runs the validation data through the model to find the validation loss. Recall that although optimization can only directly reduce the training loss, the validation loss is a better indication of how the network would perform with new examples.\n",
        "\n",
        "*Finally, run the code below to train the network for ten epochs. Note how loss and accuracy on the validation dataset change with each epoch.*"
      ],
      "metadata": {
        "id": "tjml2dfRIeaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WCnfUumdGNq",
        "outputId": "a102a622-f414-4fca-c4ac-50ccddb9e986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "............................................................Training loss: 1.0770 accuracy: 0.7015\n",
            "..........Validation loss: 0.2880 accuracy: 0.9150\n",
            "Epoch 2/10\n",
            "............................................................Training loss: 0.2719 accuracy: 0.9198\n",
            "..........Validation loss: 0.1799 accuracy: 0.9475\n",
            "Epoch 3/10\n",
            "............................................................Training loss: 0.1802 accuracy: 0.9469\n",
            "..........Validation loss: 0.1303 accuracy: 0.9599\n",
            "Epoch 4/10\n",
            "............................................................Training loss: 0.1381 accuracy: 0.9597\n",
            "..........Validation loss: 0.0973 accuracy: 0.9709\n",
            "Epoch 5/10\n",
            "............................................................Training loss: 0.1161 accuracy: 0.9662\n",
            "..........Validation loss: 0.0902 accuracy: 0.9720\n",
            "Epoch 6/10\n",
            "............................................................Training loss: 0.0985 accuracy: 0.9716\n",
            "..........Validation loss: 0.0671 accuracy: 0.9792\n",
            "Epoch 7/10\n",
            "............................................................Training loss: 0.0845 accuracy: 0.9756\n",
            "..........Validation loss: 0.0655 accuracy: 0.9787\n",
            "Epoch 8/10\n",
            "............................................................Training loss: 0.0753 accuracy: 0.9778\n",
            "..........Validation loss: 0.0567 accuracy: 0.9815\n",
            "Epoch 9/10\n",
            "............................................................Training loss: 0.0694 accuracy: 0.9797\n",
            "..........Validation loss: 0.0514 accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "............................................................Training loss: 0.0611 accuracy: 0.9818\n",
            "..........Validation loss: 0.0494 accuracy: 0.9843\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "\n",
        "    model.train() # put model in training mode\n",
        "    process_dataset(model, train_loader, optimizer=optimizer)\n",
        "\n",
        "    model.eval() # put model in evaluation mode\n",
        "    process_dataset(model, validation_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v0CMfJI4hQ76"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}